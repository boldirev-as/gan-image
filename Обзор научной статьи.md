### A Multi-modal Deep Learning Model for Video Thumbnail Selection

Осенью участвовали в хакатоне от Газпром Медиа, там была очень похожая задача, по генерации виральных видео для каких-то сериалов/выпусков. Пользовался как раз этой статьёй, чтобы собрать baseline.

___
#### **Цель исследования**
Авторы предлагают мультимодальную сеть для выбора превью видео. Особенность - объединение эмбеддингов кадров, заголовков, описаний и аудиотреков в архитектуре модели, чтобы выбрать подходящий фрагмент видео.

---

#### **Основные этапы**
1. **Предварительная обработка:**
   - Из видео выбирается каждый 9 кадр для сокращения объема данных.
   - Отобранные кадры оцениваются с использованием Double-column Convolutional Neural Network (DCNN). Выбираются 1000 лучших кадров.

2. **Извлечение признаков:**
   - **Кадры:** Используется модель VGG16 для получения эмбеддингов.
   - **Текст:** Применяется модель ELECTRA.
   - **Аудио:** Используется TRILL для эмбеддингов аудиосигналов.

3. **Обучение:**
   - Применяется Transformer для извлечения временной зависимости в кадрах и аудиотреках.

4. **Финальная обработка:**
   - Признаки из всех Transformer объединяются в единое векторное представление видео.
   - Выходное представление используется для нахождения наиболее похожего кадра среди отобранных.

---

#### **Результаты**

**Сравнение с другими методами:**
   - Модель превосходит предыдущую SOTA модель Song et al. по метрике Precision.
   - Даже при уменьшенном объеме обучающей выборки (700 видео вместо 1171), модель показывает конкурентные результаты.

 **Эффективность мультимодального подхода:**
   - Объединение данных из текста, аудио и визуальных модальностей значительно улучшило точность выбора миниатюр.

---

#### **Преимущества и ограничения**

**Преимущества:**
  - Полноценное использование мультимодальной информации для более точного выбора миниатюр.
  - Успешная интеграция трансформеров и методов извлечения признаков из различных источников.

**Ограничения:**
  - Высокая вычислительная сложность из-за необходимости обработки всех кадров.
  - Требуется высококачественный набор данных для обучения, включая метаданные и аудиотреки, особенно сложно с метками для классов.

---

#### **Заключение**

Авторы показали важность мультимодального подхода.
В будущем предлагается:
  - Упростить модель предварительной фильтрации кадров для ускорения вычислений.
  - Добавить низкоуровневые признаки, такие как отношения между объектами в кадре.
  - Исследовать улучшенные методы обучения контекста.
---
